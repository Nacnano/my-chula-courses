{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87UHAQkt5dIw"
      },
      "source": [
        "# RNN Date Generation Demo on Pytoch Lightning: Date Generation (One-to-Many)\n",
        "\n",
        "In this demo, we will show you how to create a date generator using Pytoch Lightning. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. In this demo, we create a one-to-many RNN model for generating date in the following format: e.g. \"2002-03-11\".  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIz3jAIF5dI1"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "!pip install lightning\n",
        "import lightning as L\n",
        "from lightning import Trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULHSHW5X5dJE"
      },
      "source": [
        "# Generate Dataset\n",
        "We generate a toy dataset using datetime library.  The target output only comes in one format (iso format)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km8dKUXP5dJH"
      },
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 1500)]\n",
        "data = [date.isoformat() for date in date_list]\n",
        "print(data[:5])\n",
        "maxlen=10 #all the seqeunces have 10 characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKLIr4Od5dJP"
      },
      "source": [
        "chars = list(set(''.join(data)))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('There are %d lines and %d unique characters in your data.' % (data_size, vocab_size))\n",
        "print(\"max length =\",maxlen)\n",
        "sorted_chars= sorted(chars)\n",
        "print(sorted_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO-IDo5A5dJX"
      },
      "source": [
        "# In this demo, we will use \"<S>\" as a seed character to initiate the sequence\n",
        "sorted_chars.insert(0,\"<S>\")\n",
        "vocab_size = len(sorted_chars)\n",
        "\n",
        "print(f\"All Characters: {sorted_chars}\")\n",
        "print(f\"Vocab Size: {vocab_size}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick implementation of character tokenizer\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "itos = { i:ch for i,ch in enumerate(sorted_chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"2024-10-26\"))\n",
        "print(decode(encode(\"2024-10-26\")))"
      ],
      "metadata": {
        "id": "1SiYQTFehkLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itos"
      ],
      "metadata": {
        "id": "DQ2fXwDoi48Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stoi"
      ],
      "metadata": {
        "id": "RIzWJicEjx-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRuFbBUx5dJr"
      },
      "source": [
        "# Preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw-BupZv5dJt"
      },
      "source": [
        "#Encoding data\n",
        "encoded = []\n",
        "for line in data:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    indices = encode(line)\n",
        "    encoded.append(indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKOiX5B5dJ0"
      },
      "source": [
        "class DateDataset(Dataset):\n",
        "  def __init__(self, data):\n",
        "    data = [[0] + d for d in data] # add <s> at the start of every data point\n",
        "    self.encoded = torch.LongTensor(data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.encoded[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      one_hot_x = torch.stack([F.one_hot(b, num_classes=vocab_size) for b in batch])\n",
        "      return {\"x\": one_hot_x.float(), \"y\": torch.stack(batch)}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_dataset = DateDataset(self.train_data)\n",
        "      train_loader = DataLoader(train_dataset,\n",
        "                                batch_size = self.batch_size,\n",
        "                                shuffle = True,\n",
        "                                collate_fn = self.collate_fn,\n",
        "                                num_workers = self.num_workers)\n",
        "\n",
        "      return train_loader"
      ],
      "metadata": {
        "id": "Q0MWLXPzJaZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "data_module = DateDataModule(encoded, batch_size=batch_size,num_workers=0)"
      ],
      "metadata": {
        "id": "90IQfib5OYJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmXcPnNi5dJ9"
      },
      "source": [
        "# Create & train model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(L.LightningModule):\n",
        "    def __init__(self, vocab_size, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.hidden_dim = 16\n",
        "        self.vocab_size = vocab_size\n",
        "        self.rnn = nn.RNNCell(self.vocab_size, self.hidden_dim)\n",
        "\n",
        "        self.fc = nn.Linear(self.hidden_dim, self.vocab_size)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "\n",
        "    def forward(self, src, hx):\n",
        "        hx = self.rnn(src, hx)\n",
        "        prediction_logit = self.fc(hx)\n",
        "        return prediction_logit, hx\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x'][:, :-1]\n",
        "        target = batch['y'][:, 1:]\n",
        "        temp = []\n",
        "        hx = torch.randn(src.shape[0], self.hidden_dim).to(self.rnn.weight_ih.device)\n",
        "        prediction = torch.zeros((src.shape[0], src.shape[1], self.vocab_size) ,device=hx.device)\n",
        "\n",
        "        for i in range(src.shape[1]):\n",
        "          prediction_logit, hx = self(src[:,i], hx)\n",
        "          prediction[:, i, :] = prediction_logit\n",
        "\n",
        "        prediction = prediction.reshape(-1, vocab_size)\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "YKKPBWnCJppN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "vocab_size = vocab_size\n",
        "lr = 0.005\n",
        "model = SimpleRNN(vocab_size, lr, criterion)"
      ],
      "metadata": {
        "id": "0w5KTNVpKKVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output_list = []\n",
        "    input = F.one_hot(torch.zeros([1], dtype=torch.long), num_classes=vocab_size)\n",
        "    input = input.float()\n",
        "    input = input.to(model.device)\n",
        "    hx = torch.randn(input.shape[0], 16).to(model.device)\n",
        "    for i in range(10):\n",
        "      logit, hx = model(input, hx)\n",
        "      prob = F.softmax(logit, dim=-1)\n",
        "      pred = torch.multinomial(prob, 1)\n",
        "      output = pred.item()\n",
        "      output_list.append(output)\n",
        "\n",
        "      input = F.one_hot(torch.tensor([output], dtype=torch.long), num_classes=vocab_size)\n",
        "      input = input.float()\n",
        "      input = input.to(model.device)\n",
        "  return decode(output_list)"
      ],
      "metadata": {
        "id": "wSpkkvTOTMRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PrintCallback(L.pytorch.callbacks.Callback):\n",
        "  def __init__(self, what=\"epochs\", verbose=True):\n",
        "        self.what = what\n",
        "        self.verbose = verbose\n",
        "        self.state = {\"epochs\": 0, \"batches\": 0}\n",
        "\n",
        "  def on_train_epoch_end(self, *args, **kwargs):\n",
        "        if self.what == \"epochs\":\n",
        "            self.state[\"epochs\"] += 1\n",
        "        if self.state[\"epochs\"] % 2 == 0:\n",
        "            print('----- Generating text after Epoch: %d' % self.state[\"epochs\"])\n",
        "            for i in range(3):\n",
        "              print(generate(model))\n"
      ],
      "metadata": {
        "id": "qvujPMWdPbDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        "    callbacks=[PrintCallback()]\n",
        ")"
      ],
      "metadata": {
        "id": "NeTcVNQmO3aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4M8URGW5dK0"
      },
      "source": [
        "# Let's train the model and generate some text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3): #before training\n",
        "  print(generate(model))"
      ],
      "metadata": {
        "id": "QvtvwwwSqpAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "cTVJ8ZGFO5W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(generate(model))"
      ],
      "metadata": {
        "id": "voYlHp7cWyAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhpse2Wl1-QR"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}