{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUmXr1D1ZSR"
      },
      "source": [
        "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
        "\n",
        "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning wandb\n",
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
      ],
      "metadata": {
        "id": "18KMSkqZ-Pt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBCWKARZEx",
        "outputId": "6ad8a585-fd68-44ee-deac-37143137cbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2TN8IV1ZSU"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "import torch\n",
        "# import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f_s6vX1ZSZ"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "```\n",
        "ไกรสีห์ kraisi\n",
        "พัชรี phatri\n",
        "ธีระ thira\n",
        "วุฒิกร wutthikon\n",
        "ไสว sawai\n",
        "สัมภาษณ์  samphat\n",
        "วศิน wasin\n",
        "ทินวัฒน์ thinwat\n",
        "ศักดินัย sakdinai\n",
        "สุรศักดิ์ surasak\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "metadata": {
        "id": "Jte-Csrf-4kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1ba364b-64c2-4875-873c-90bc1808a4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-04 07:15:34--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-02-04 07:15:35 (71.4 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zXp7KH1ZSa"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        temp_th = row[0]\n",
        "        temp_en = row[1]\n",
        "\n",
        "        name_th.append(temp_th)\n",
        "        name_en.append(temp_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCsqrXxu1ZSe"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvW8xqT81ZSh"
      },
      "source": [
        "## TODO1: Preprocess dataset\n",
        "* You will need 2 vocabularies (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rv1Xd9A1ZSi",
        "outputId": "dece74ae-a492-41a7-f07d-2798157c7fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(name_th, key=len)) #max input length\n",
        "maxlen_out = len( max(name_en, key=len)) #max input length"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10887 lines and 65 unique characters in your input data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo381I_t1ZSm",
        "outputId": "4467516a-90c8-477d-bc43-bb071b17a956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Max input length:\", maxlen)\n",
        "print(\"Max output length:\", maxlen_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input length: 20\n",
            "Max output length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "W3aXyJBEC-j_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    pass\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    pass\n",
        "\n",
        "  def __len__(self):\n",
        "    pass"
      ],
      "metadata": {
        "id": "-yirzlseC9NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    pass\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "qUPAB7LTDFOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSG1FqK1ZSy"
      },
      "source": [
        "# Attention Mechanism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 2: Code your own (key-value) attention mechnism\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* fill code for one_step_attention function\n",
        "\n"
      ],
      "metadata": {
        "id": "HAlOrhbismQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(h, s_prev, ...):\n",
        "\n",
        "    #Split into Key-Value\n",
        "    key, value = torch.split(...)\n",
        "    #do concat with s_prev.\n",
        "    #hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
        "    #hint2: s_prev.unsqueeze() could also be useful\n",
        "\n",
        "\n",
        "    #Attention function###\n",
        "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
        "    # calculate a context vector\n",
        "\n",
        "    return ..."
      ],
      "metadata": {
        "id": "avnlc6p9BZDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Model"
      ],
      "metadata": {
        "id": "6zWN02ZtuOIU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyUQYg1ZS8"
      },
      "source": [
        "## TODO3: Create and train your encoder/decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_rUPhK1ZS9"
      },
      "source": [
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = #hidden dimensions for encoder\n",
        "        self.n_s = #hidden dimensions for decoder\n",
        "\n",
        "        #encoder can be any RNN of your choice\n",
        "\n",
        "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_vocab))\n",
        "        #attention\n",
        "\n",
        "\n",
        "    def forward(self, src, return_attention=False): #use return_attention only when you want to get the attention scores for visualizing\n",
        "        #pass the input to the encoder\n",
        "\n",
        "        #Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
        "        #These states will get updated while we are decoding\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        #Iterate until max_output_length (Decoding)\n",
        "        prediction = torch.zeros((src.shape[0], \"max_output_length\", len(output_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        attention_scores = [] #to store the score for each step\n",
        "        for t in range(...):\n",
        "\n",
        "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context, attention_score = one_step_attention(...)\n",
        "\n",
        "            # Feed the context vector to the decoder.\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "\n",
        "            # Put the predicted output into the list for this timestep\n",
        "            prediction[:, t] = out\n",
        "\n",
        "        return (prediction, attention_scores if return_attention else None)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction,_ = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_vocab))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction, attention_scores = self(src, return_attention=True)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(\"\".join(output_vocab.lookup_tokens(pred.cpu().numpy())))\n",
        "        return prediction, attention_scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AttentionModel()"
      ],
      "metadata": {
        "id": "pSM9dgDcCz1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = NameDataModule(X, Y)"
      ],
      "metadata": {
        "id": "RqrvmJalDLzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import Trainer\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"hw3.1_attention\")"
      ],
      "metadata": {
        "id": "_sFjzKX8SECo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGWSzS-X1ZTO"
      },
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=100,\n",
        "    logger=wandb_logger\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMi782c1ZTQ"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5BLw1Ir1ZTT"
      },
      "source": [
        "# Test Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO4: Test your model on 5 examples of your choice including your name!\n",
        "\n",
        "Example Output:\n",
        "```\n",
        "prayutthatha</s></s>aa</s></s>a</s>\n",
        "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
        "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
        "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
        "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "chatchachatti</s></s>i</s></s></s></s>\n",
        "```\n",
        "\n",
        "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
      ],
      "metadata": {
        "id": "VRLjZzBMtCdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['ประยุทธ','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ']"
      ],
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "kbolC8XIhR3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(model, predict_loader)"
      ],
      "metadata": {
        "id": "LsN71S9uQ9wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o3893RL1ZT8"
      },
      "source": [
        "## TODO 5: Show your visualization of attention scores on one of your example\n",
        "\n",
        "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHysSqYJ1ZUA"
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdktVnMv1ZTh"
      },
      "source": [
        "prediction, attention_scores = zip(*output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_yticklabels(output_text,rotation=30)\n",
        "ax.set_xticklabels(xlabels,rotation=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "BF6HD99lYlgQ",
        "outputId": "caaa0716-5b99-43e8-950f-dd0127d0fbb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1UkIsCztaMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}