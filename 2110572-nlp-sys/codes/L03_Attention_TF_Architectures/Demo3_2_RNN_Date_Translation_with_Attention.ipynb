{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Additive Attention from scratch"
      ],
      "metadata": {
        "id": "0u4d0nVRMVgG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB0ipHig9gOm"
      },
      "source": [
        "## Attention Mechanism Demo on Pytorch: Machine Translation Example (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this demo, we will show you how to create a machine translator using Pytorch. This demo is inspired by Andrew Ng's deeplearning.ai course on sequence models. (Programming Assignment: Neural Machine Translation with Attention)    In this demo, we create a machine translator to translate dates in various formats  into dates in an ISO format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_clL4w89gOt"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "!pip install lightning\n",
        "import lightning as L\n",
        "from lightning import Trainer\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEyHEfFt9gO9"
      },
      "source": [
        "## Generate Dataset\n",
        "We generate a toy dataset using datetime library.  A target output only comes in one format (iso format), while there are three different date format for an input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWRgqvwY9gO_"
      },
      "source": [
        "#Generating a toy dataset\n",
        "import datetime\n",
        "base = datetime.datetime.today()\n",
        "base = datetime.date(base.year, base.month, base.day)\n",
        "date_list = [base - datetime.timedelta(days=x) for x in range(0, 15000)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrNHzgFy9gPI"
      },
      "source": [
        "target_date_list = [date.isoformat() for date in date_list]\n",
        "print(target_date_list[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT7V4FJL9gPR"
      },
      "source": [
        "from random import randint\n",
        "random.seed(42)\n",
        "input_date_list = list()\n",
        "for date in date_list:\n",
        "    random_num = randint(0, 2)\n",
        "    if random_num == 0:\n",
        "        input_date_list.append(date.strftime(\"%d/%m/%y\"))#\"11/03/02\"\n",
        "    elif random_num == 1:\n",
        "        input_date_list.append(date.strftime(\"%A %d %B %Y\")) #\"Monday 11 March 2002\"\n",
        "    elif random_num == 2:\n",
        "        input_date_list.append(date.strftime(\"%d %B %Y\")) #\"11 March 2002\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfXKy2y9gPZ"
      },
      "source": [
        "for input_sample, target_sample in zip(input_date_list[0:10],target_date_list[0:10]):\n",
        "    print(input_sample,target_sample)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KndjKsS9gPg"
      },
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(input_date_list)))\n",
        "output_chars = list(set(''.join(target_date_list)))\n",
        "\n",
        "# +1 for padding\n",
        "data_size, vocab_size = len(input_date_list), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+1\n",
        "\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(input_date_list, key=len)) #max input length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K-0kaUH9gPn"
      },
      "source": [
        "print(\"Max input length:\", maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_chars= sorted(input_chars)\n",
        "sorted_output_chars= sorted(output_chars)\n",
        "sorted_chars.insert(0,\"<PAD>\") #PADDING for input\n",
        "sorted_output_chars.insert(0,\"<PAD>\") #PADDING for output\n",
        "\n",
        "# Quick implementation of character tokenizer\n",
        "# create a mapping from characters to integers\n",
        "input_stoi = { ch:i for i,ch in enumerate(sorted_chars) }\n",
        "input_itos = { i:ch for i,ch in enumerate(sorted_chars) }\n",
        "input_encode = lambda s: [input_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "input_decode = lambda l: ''.join([input_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "\n",
        "output_stoi = { ch:i for i,ch in enumerate(sorted_output_chars) }\n",
        "output_itos = { i:ch for i,ch in enumerate(sorted_output_chars) }\n",
        "output_encode = lambda s: [output_stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "output_decode = lambda l: ''.join([output_itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(input_encode(\"22/12/24\"))\n",
        "print(input_decode(input_encode(\"22/12/24\")))"
      ],
      "metadata": {
        "id": "YaP2TKsD1UOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_stoi)\n",
        "print(output_stoi)"
      ],
      "metadata": {
        "id": "ulW7bT9V1pS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q0XsxhL9gP2"
      },
      "source": [
        "m=15000\n",
        "Tx=maxlen\n",
        "Ty=10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvKOfVnc9gP-"
      },
      "source": [
        "X = []\n",
        "for line in input_date_list:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in target_date_list:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "trjH1DiZ3yyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.encoded = X.long()\n",
        "    self.label = torch.stack(y).long()\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"x\" :self.encoded[idx], \"y\":self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ],
      "metadata": {
        "id": "9khoV30W33US"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "      one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "      return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "      train_dataset = DateDataset(self.train_data, self.y)\n",
        "      train_loader = DataLoader(train_dataset,\n",
        "                                batch_size = self.batch_size,\n",
        "                                shuffle = True,\n",
        "                                collate_fn = self.collate_fn,\n",
        "                                num_workers = self.num_workers)\n",
        "\n",
        "      return train_loader"
      ],
      "metadata": {
        "id": "Z1ONZO0S3_qt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "data_module = DateDataModule(X, Y, batch_size=batch_size,num_workers=0)"
      ],
      "metadata": {
        "id": "vHtxahO54IfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFYhwzdj9gQG"
      },
      "source": [
        "## Attention Mechanism\n",
        "![attn_mech](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/attn_mech.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(h, s_prev, linear_1, linear_2):\n",
        "    #h.shape = batch, seq_len, hidden_dim\n",
        "    #s_prev.shape = batch, hidden_dim\n",
        "    # #linear_1 and linear_2 are linear layers in the model\n",
        "    s_prev = s_prev.unsqueeze(1).repeat((1, h.shape[1], 1))\n",
        "    concat = torch.cat([h, s_prev], dim=-1) #concat.shape = batch, seq_len, hidden_dim*2\n",
        "\n",
        "    #Attention function###\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    energies = F.relu(linear_2(e))\n",
        "    # calculate attention_scores (softmax)\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    # calculate a context vector\n",
        "    temp = torch.mul(attention_scores, h)\n",
        "    context = torch.sum(temp,dim=1)\n",
        "\n",
        "    return context"
      ],
      "metadata": {
        "id": "ry5bLZjX4pwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv475_JS9gQY"
      },
      "source": [
        "## The model\n",
        "![rnn_model](https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/rnn_date.png)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32 #hidden dimensions for encoder\n",
        "        self.n_s = 64 #hidden dimensions for decoder\n",
        "\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "        #encoder\n",
        "        bidirection = True\n",
        "        self.num_directions = 2 if bidirection else 1\n",
        "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=bidirection, batch_first=True)\n",
        "        #decoder\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_stoi))\n",
        "        #attention\n",
        "        self.fc1 = nn.Linear(self.n_h*2*self.num_directions, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "    def forward(self, src):\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        prediction = torch.zeros((src.shape[0], Ty, len(output_stoi))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        #Iterate for Ty steps (Decoding)\n",
        "        for t in range(Ty):\n",
        "\n",
        "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
        "            # Feed the context vector to the decoder LSTM cell\n",
        "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
        "\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "            out = self.output_layer(decoder_s)\n",
        "\n",
        "            # Append an output list with the current output\n",
        "            prediction[:, t] = out\n",
        "        return prediction\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_stoi))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction = self(src)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(output_decode(pred.cpu().numpy()))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "metadata": {
        "id": "C0PIR2vV4MLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel(lr, criterion)"
      ],
      "metadata": {
        "id": "d6VHTvyoFuxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    max_epochs=10,\n",
        ")"
      ],
      "metadata": {
        "id": "tYColP-nGW5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "metadata": {
        "id": "rD1UelkcGZSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePf2CDQb9gQ-"
      },
      "source": [
        "## Let's do some \"translation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['Monday 15 March 2025', '3 May 1999', '05 October 2009', '30 August 2016', '11 July 2000', 'Saturday 19 May 2018', '3 March 2001', '1 March 2001']\n",
        "predict_data = []\n",
        "for line in EXAMPLES:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    predict_data.append(torch.tensor(input_encode(line)))\n",
        "\n",
        "print(len(predict_data))\n",
        "def collate_fn(batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float()}\n",
        "\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n",
        "predict_dataset = DateDataset(predict_data, [torch.tensor(0)]*len(predict_data))\n",
        "predict_loader = DataLoader(predict_dataset,\n",
        "                          batch_size = 1,\n",
        "                          shuffle = False,\n",
        "                          collate_fn = collate_fn,\n",
        "                          num_workers = 0)"
      ],
      "metadata": {
        "id": "6stNACsUP9h-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.predict(model, predict_loader)"
      ],
      "metadata": {
        "id": "LsN71S9uQ9wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}