{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# HOMEWORK 6: TEXT CLASSIFICATION\nIn this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n\nWe will focus only on the Object Classification task for this homework.\n\nIn this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n\nYou will need to build 3 different models.\n\n1. A model based on tf-idf\n2. A model based on MUSE\n3. A model based on wangchanBERTa\n\n**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n\nThis homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification.","metadata":{"id":"VQ8FRFIYMc5X"}},{"cell_type":"code","source":"!wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv","metadata":{"id":"kHqkFSyaNvOt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"879b17f1-0fb2-455c-ca37-b5a4aecd7b1c","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:25:49.251579Z","iopub.execute_input":"2025-02-15T17:25:49.251962Z","iopub.status.idle":"2025-02-15T17:25:50.528690Z","shell.execute_reply.started":"2025-02-15T17:25:49.251931Z","shell.execute_reply":"2025-02-15T17:25:50.527846Z"}},"outputs":[{"name":"stdout","text":"--2025-02-15 17:25:49--  https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\nResolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:6018:18::a27d:312\nConnecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://www.dropbox.com/scl/fi/8h8hvsw9uj6o0524lfe4i/clean-phone-data-for-students.csv?rlkey=lwv5xbf16jerehnv3lfgq5ue6 [following]\n--2025-02-15 17:25:49--  https://www.dropbox.com/scl/fi/8h8hvsw9uj6o0524lfe4i/clean-phone-data-for-students.csv?rlkey=lwv5xbf16jerehnv3lfgq5ue6\nReusing existing connection to www.dropbox.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com/cd/0/inline/CkKTYFCxdlz7-k1p7pp6ebl7mdHz3qc9Me3wCOfH7Qpj7N2tzFBWDmdb9ghn5fc5B0bYSN7Tl29IaoqMKf8YBtC4PAviOqFCeB2KcTZJkgOpMXJqVbbmbPP6Dt2s1xG4MKs/file# [following]\n--2025-02-15 17:25:49--  https://ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com/cd/0/inline/CkKTYFCxdlz7-k1p7pp6ebl7mdHz3qc9Me3wCOfH7Qpj7N2tzFBWDmdb9ghn5fc5B0bYSN7Tl29IaoqMKf8YBtC4PAviOqFCeB2KcTZJkgOpMXJqVbbmbPP6Dt2s1xG4MKs/file\nResolving ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com (ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\nConnecting to ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com (ucd140658d06553ba0fb5f39edc4.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2518977 (2.4M) [text/plain]\nSaving to: ‘clean-phone-data-for-students.csv.1’\n\nclean-phone-data-fo 100%[===================>]   2.40M  --.-KB/s    in 0.08s   \n\n2025-02-15 17:25:50 (30.4 MB/s) - ‘clean-phone-data-for-students.csv.1’ saved [2518977/2518977]\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install pythainlp\n!pip install -U sentence-transformers\n!pip install tf-keras","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRlx5Mb5zkXw","outputId":"18d913e0-aa6d-435b-931d-591386cb4ba8","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:25:50.530141Z","iopub.execute_input":"2025-02-15T17:25:50.530587Z","iopub.status.idle":"2025-02-15T17:26:00.748310Z","shell.execute_reply.started":"2025-02-15T17:25:50.530559Z","shell.execute_reply":"2025-02-15T17:26:00.747213Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.5)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2025.1.31)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.4.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.47.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.28.1)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tf-keras in /usr/local/lib/python3.10/dist-packages (2.17.0)\nRequirement already satisfied: tensorflow<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tf-keras) (2.17.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.12.1)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.4.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (24.2)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (75.1.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.5.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.17.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.68.1)\nRequirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.1)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (3.5.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (0.37.1)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.18,>=2.17->tf-keras) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.18,>=2.17->tf-keras) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow<2.18,>=2.17->tf-keras) (2025.1.31)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow<2.18,>=2.17->tf-keras) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow<2.18,>=2.17->tf-keras) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.2)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Import Libs","metadata":{"id":"2YprqbOPMc5a"}},{"cell_type":"code","source":"%matplotlib inline\nimport pandas\nimport sklearn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom torch.utils.data import Dataset\nfrom IPython.display import display\nfrom collections import defaultdict\nfrom sklearn.metrics import accuracy_score","metadata":{"id":"heICP79cMc5e","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:26:00.750210Z","iopub.execute_input":"2025-02-15T17:26:00.750541Z","iopub.status.idle":"2025-02-15T17:26:00.757110Z","shell.execute_reply.started":"2025-02-15T17:26:00.750506Z","shell.execute_reply":"2025-02-15T17:26:00.756305Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"data_df = pd.read_csv('clean-phone-data-for-students.csv')","metadata":{"id":"JhZ2eBAWMc5l","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:26:00.758448Z","iopub.execute_input":"2025-02-15T17:26:00.758762Z","iopub.status.idle":"2025-02-15T17:26:00.838615Z","shell.execute_reply.started":"2025-02-15T17:26:00.758735Z","shell.execute_reply":"2025-02-15T17:26:00.837664Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def clean_data(df):\n    \"\"\"Cleans the dataset by selecting relevant columns, normalizing labels, \n    trimming whitespace, and removing duplicates.\"\"\"\n    \n    # Select and rename columns\n    df = df[[\"Sentence Utterance\", \"Object\"]].rename(columns={\"Sentence Utterance\": \"input\", \"Object\": \"raw_label\"})\n\n    # Normalize label (lowercase)\n    df[\"clean_label\"] = df[\"raw_label\"].str.lower()\n\n    # Trim white spaces in input column\n    df[\"input\"] = df[\"input\"].str.strip()\n\n    # Remove duplicates based on input\n    df = df.drop_duplicates(subset=\"input\", keep=\"first\")\n\n    # Drop the raw label column\n    df.drop(columns=[\"raw_label\"], inplace=True)\n\n    return df\n\n# Apply cleaning function\ndata_df = clean_data(data_df)\n\n# Display summary\ndisplay(data_df.describe())\ndisplay(data_df[\"clean_label\"].unique())\n","metadata":{"id":"19onNNUZMc54","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:26:00.839682Z","iopub.execute_input":"2025-02-15T17:26:00.840019Z","iopub.status.idle":"2025-02-15T17:26:00.877667Z","shell.execute_reply.started":"2025-02-15T17:26:00.839989Z","shell.execute_reply":"2025-02-15T17:26:00.877000Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                       input clean_label\ncount                                  13367       13367\nunique                                 13367          26\ntop     สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ     service\nfreq                                       1        2108","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>input</th>\n      <th>clean_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>13367</td>\n      <td>13367</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>13367</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ</td>\n      <td>service</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>2108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n      dtype=object)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Mapping and Trimming\ndata = data_df.to_numpy()\nunique_label = data_df.clean_label.unique()\n\nlabel_2_num_map = dict(zip(unique_label, range(len(unique_label))))\nnum_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n\ndata[:,1] = np.vectorize(label_2_num_map.get)(data[:,1]) \n\ndef strip_str(string):\n    return string.strip()\ndata[:,0] = np.vectorize(strip_str)(data[:,0])\n\ndisplay(data)","metadata":{"id":"EYzMrvb7nYR2","execution":{"iopub.status.busy":"2025-02-15T17:26:00.878496Z","iopub.execute_input":"2025-02-15T17:26:00.878740Z","iopub.status.idle":"2025-02-15T17:26:00.915802Z","shell.execute_reply.started":"2025-02-15T17:26:00.878719Z","shell.execute_reply":"2025-02-15T17:26:00.915120Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"array([['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท',\n        0],\n       ['internet ยังความเร็วอยุ่เท่าไหร ครับ', 1],\n       ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ', 2],\n       ...,\n       ['ยอดเงินเหลือเท่าไหร่ค่ะ', 7],\n       ['ยอดเงินในระบบ', 7],\n       ['สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ', 1]], dtype=object)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Split\nfrom sklearn.model_selection import train_test_split\n\n# Constants\nSEED = 42\nMIN_INSTANCES = 10  # Minimum instances per class\n\n\ndef filter_data(data_df, min_instances=MIN_INSTANCES):\n    \"\"\"\n    Filters classes with fewer than `min_instances` occurrences.\n    Returns filtered input (X) and labels (y).\n    \"\"\"\n    class_counts = data_df[\"clean_label\"].value_counts()\n    valid_classes = class_counts[class_counts >= min_instances].index\n\n    filtered_data = data_df[data_df[\"clean_label\"].isin(valid_classes)]\n    return filtered_data[\"input\"], filtered_data[\"clean_label\"].astype(int)\n\ndef split_data(data_df, random_state=SEED, min_instances=MIN_INSTANCES):\n    \"\"\"\n    Splits data into train (80%), validation (10%), and test (10%) sets.\n    Ensures stratification and filtering of rare classes.\n    \"\"\"\n    # Filter classes\n    X, y = filter_data(data_df, min_instances)\n\n    # Split 80% Train, 20% Temp\n    X_train, X_temp, y_train, y_temp = train_test_split(\n        X, y, test_size=0.20, stratify=y, random_state=random_state\n    )\n\n    # Split 10% Validation, 10% Test\n    X_val, X_test, y_val, y_test = train_test_split(\n        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=random_state\n    )\n\n    print(f\"Train size: {len(X_train)}\")\n    print(f\"Validation size: {len(X_val)}\")\n    print(f\"Test size: {len(X_test)}\")\n\n    return (\n        np.array(X_train), np.array(X_val), np.array(X_test),\n        np.array(y_train), np.array(y_val), np.array(y_test)\n    )\n\n# Convert to DataFrame\ndf = pd.DataFrame(data, columns=['input', 'clean_label'])\n\n# Split dataset\nX_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:26:00.916556Z","iopub.execute_input":"2025-02-15T17:26:00.916758Z","iopub.status.idle":"2025-02-15T17:26:00.942865Z","shell.execute_reply.started":"2025-02-15T17:26:00.916741Z","shell.execute_reply":"2025-02-15T17:26:00.941881Z"}},"outputs":[{"name":"stdout","text":"Train size: 10690\nValidation size: 1336\nTest size: 1337\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Model 2 MUSE\n\nBuild a simple logistic regression model using features from the MUSE model.\n\nWhich MUSE model will you use? Why?\n\n**Ans:**  I will use sentence-transformers/use-cmlm-multilingual because:\n\n- It is pre-trained on multiple languages, including Thai, ensuring better language coverage.\n- It captures sentence-level semantics rather than just individual words, leading to more meaningful embeddings.\n- It generalizes better than traditional vector-based models like TF-IDF, improving performance in downstream tasks.\n\nMUSE is typically used with tensorflow. However, there are some pytorch conversions made by some people.\n\nhttps://huggingface.co/sentence-transformers/use-cmlm-multilingual\nhttps://huggingface.co/dayyass/universal-sentence-encoder-multilingual-large-3-pytorch","metadata":{"id":"wql2YeU8qFQ6"}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.linear_model import LogisticRegression\nstart_time = time.time()\nprint(\"MUSE + Logistic Regression\")\n\nmuse_model = SentenceTransformer(\"sentence-transformers/use-cmlm-multilingual\")\n\ndef encode_texts(texts):\n    return muse_model.encode(texts, convert_to_numpy=True)\n\nstart_enc_time = time.time()\nX_train_enc = encode_texts(X_train.tolist())\nX_val_enc = encode_texts(X_val.tolist())\nX_test_enc = encode_texts(X_test.tolist())\nend_enc_time = time.time()\nprint(f\"Encoding Time: {end_enc_time - start_enc_time:.4f} seconds\")\n\nmodel = LogisticRegression(random_state=SEED)\n\nstart_train_time = time.time()\nmodel.fit(X_train_enc, y_train)\nend_train_time = time.time()\nprint(f\"Training Time: {end_train_time - start_train_time:.4f} seconds\")\n\ny_pred_train = model.predict(X_train_enc)\ny_pred_val = model.predict(X_val_enc)\ny_pred_test = model.predict(X_test_enc)\n\ntrain_acc = np.mean(y_train.astype(int) == y_pred_train)\nval_acc = np.mean(y_val.astype(int) == y_pred_val)\ntest_acc = np.mean(y_test.astype(int) == y_pred_test)\n\nprint(f\"Train Accuracy: {train_acc:.4f}\")\nprint(f\"Validation Accuracy: {val_acc:.4f}\")\nprint(f\"Test Accuracy: {test_acc:.4f}\")\nend_time = time.time()\nprint(f\"Total Time: {end_time - start_time:.4f} seconds\")","metadata":{"id":"d3UtkpaLnctH","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T17:26:45.028263Z","iopub.execute_input":"2025-02-15T17:26:45.028585Z","iopub.status.idle":"2025-02-15T17:27:51.403321Z","shell.execute_reply.started":"2025-02-15T17:26:45.028562Z","shell.execute_reply":"2025-02-15T17:27:51.402206Z"}},"outputs":[{"name":"stdout","text":"MUSE + Logistic Regression\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"989b24c6231f4c1897190e1e8bbf71df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48248e8130354129b17eb409cda3a458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.89k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d356c37e628c4511b4ef235f46ea564b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e91200f367c4930861e909c3cbf30ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb15376b321d4203beb31dceec1e4de5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed2161d3aad04da0b4fc86e0ca4616a1"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at sentence-transformers/use-cmlm-multilingual were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e553f244937f479ba514ba4d4b532531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44cd7245ed624b5cbb978752ae579534"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a6ecf76c16d42be9d97b9a9be7b88cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2669f8819ad4bb7b29ef6cbc1e00adc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling%2Fconfig.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99eb8e02259841b6a67a2be0c1f288ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/335 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0e527b97104cf7891ab99b88962718"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/42 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37b7df74d03e4631b63dcee7d1e14789"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/42 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"975c55649cbc4ea9a727b5a7685de82a"}},"metadata":{}},{"name":"stdout","text":"Encoding Time: 21.6718 seconds\nTraining Time: 2.2648 seconds\nTrain Accuracy: 0.7373\nValidation Accuracy: 0.7073\nTest Accuracy: 0.7023\nTotal Time: 38.5585 seconds\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Comparison\n\nAfter you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville.","metadata":{"id":"Qr9_0DnMBcFZ"}}]}